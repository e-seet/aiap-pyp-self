{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eed8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "# Import necessary libraries\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"4\"\n",
    "\n",
    "import setup.setup as setup\n",
    "import setup.duration_cal as duration_cal\n",
    "importlib.reload(setup)  # Reload the module to reflect new changes\n",
    "\n",
    "import EDA.eda_step as EDA\n",
    "import model_select.model_select as model_select\n",
    "import model_eval.model_eval as model_eval\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from typing import Dict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6080166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load configuration and setup parameters\n",
    "start_time = time.time()\n",
    "\n",
    "(\n",
    "    db_path,\n",
    "    target_col,\n",
    "    num_map_dict,\n",
    "    standard_list,\n",
    "    one_hot_list,\n",
    "    model_test_size,\n",
    "    model_random_state,\n",
    "    model_search_method,\n",
    "    model_cv_num,\n",
    "    model_scoring,\n",
    "    model_num_iter,\n",
    "    model_num_jobs,\n",
    "    model_param_dict,\n",
    ") = setup.setup_stage_v1()\n",
    "\n",
    "print(\"Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baaa85a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Connecting to SQL database....\n",
      "Connection done!\n"
     ]
    }
   ],
   "source": [
    "# Create connection to SQL database\n",
    "print(\"1. Connecting to SQL database....\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "print(\"Connection done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d75a2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1 has run for 0.022 sec!\n"
     ]
    }
   ],
   "source": [
    "part1_time = time.time()\n",
    "part1_duration, part1_tag = duration_cal.duration_cal(part1_time - start_time)\n",
    "print(f\"Part 1 has run for {part1_duration:.3f} {part1_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b994bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Extract SQL database table as DataFrame...\n",
      "Extraction done!\n"
     ]
    }
   ],
   "source": [
    "# Get data from 'noshow' table\n",
    "print(\"2. Extract SQL database table as DataFrame...\")\n",
    "\n",
    "noshow_data_query = \"SELECT * FROM noshow;\"\n",
    "noshow_data_df = pd.read_sql_query(noshow_data_query, conn)\n",
    "\n",
    "print(\"Extraction done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16dd7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 has run for 0.512 sec!\n"
     ]
    }
   ],
   "source": [
    "part2_time = time.time()\n",
    "\n",
    "part2_duration, part2_tag = duration_cal.duration_cal(part2_time - part1_time)\n",
    "\n",
    "print(f\"Part 2 has run for {part2_duration:.3f} {part2_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202965b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Performing EDA on DataFrame...\n",
      "EDA done!\n"
     ]
    }
   ],
   "source": [
    "# Using analysis from task_1 EDA, perform data preprocessing, feature data standardization and one-hot encoding\n",
    "print(\"3. Performing EDA on DataFrame...\")\n",
    "\n",
    "fil_noshow_data_df, preprocessor, X_train, X_test, Y_train, Y_test = EDA.ml_eda_step(\n",
    "    noshow_data_df,\n",
    "    target_col,\n",
    "    num_map_dict,\n",
    "    standard_list,\n",
    "    one_hot_list,\n",
    "    model_test_size,\n",
    "    model_random_state,\n",
    ")\n",
    "\n",
    "print(\"EDA done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43d31a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 has run for 5.116 sec!\n"
     ]
    }
   ],
   "source": [
    "part3_time = time.time()\n",
    "\n",
    "part3_duration, part3_tag = duration_cal.duration_cal(part3_time - part2_time)\n",
    "\n",
    "print(f\"Part 3 has run for {part3_duration:.3f} {part3_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a7dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Training machine learning models...\n"
     ]
    }
   ],
   "source": [
    "best_estimators_dict = {}\n",
    "# Pre-select a few models and train models to get best optimized parameters\n",
    "print(\"4. Training machine learning models...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4604647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Logistic Regression\n",
    "# if \"Logistic Regression\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing Logistic Regression now...\")\n",
    "    \n",
    "#     model = LogisticRegression(random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"Logistic Regression\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"Logistic Regression\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "#     with tqdm(total=100, desc=\"Progress\", bar_format=\"{l_bar}{bar} [ time left: {remaining} ]\") as pbar:\n",
    "#         search.fit(X_train, Y_train)\n",
    "#         pbar.update(100)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"Logistic Regression\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for Logistic Regression:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"Logistic Regression has run tuning for {model_duration:.3f} {model_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "907ba669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Random Forest\n",
    "# if \"Random Forest\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing Random Forest now...\")\n",
    "    \n",
    "#     model = RandomForestClassifier(random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"Random Forest\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"Random Forest\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"Random Forest\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for Random Forest:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"Random Forest has run tuning for {model_duration:.3f} {model_tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6db110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SVC now...\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "[CV 1/3; 1/32] START model__C=0.1, model__class_weight=balanced, model__kernel=linear\n",
      "[CV 2/3; 1/32] START model__C=0.1, model__class_weight=balanced, model__kernel=linear\n",
      "[CV 3/3; 1/32] START model__C=0.1, model__class_weight=balanced, model__kernel=linear\n",
      "[CV 1/3; 2/32] START model__C=0.1, model__class_weight=balanced, model__kernel=rbf\n",
      "[CV 2/3; 1/32] END model__C=0.1, model__class_weight=balanced, model__kernel=linear;, score=-0.309 total time=16.7min\n",
      "[CV 2/3; 2/32] START model__C=0.1, model__class_weight=balanced, model__kernel=rbf\n",
      "[CV 1/3; 1/32] END model__C=0.1, model__class_weight=balanced, model__kernel=linear;, score=-0.332 total time=17.5min\n",
      "[CV 3/3; 2/32] START model__C=0.1, model__class_weight=balanced, model__kernel=rbf\n",
      "[CV 3/3; 1/32] END model__C=0.1, model__class_weight=balanced, model__kernel=linear;, score=-0.312 total time=20.7min\n",
      "[CV 1/3; 3/32] START model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=linear\n",
      "[CV 1/3; 2/32] END model__C=0.1, model__class_weight=balanced, model__kernel=rbf;, score=-0.317 total time=21.8min\n",
      "[CV 2/3; 3/32] START model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=linear\n",
      "[CV 2/3; 2/32] END model__C=0.1, model__class_weight=balanced, model__kernel=rbf;, score=-0.299 total time=21.4min\n",
      "[CV 3/3; 3/32] START model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=linear\n",
      "[CV 2/3; 3/32] END model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=linear;, score=-0.337 total time=19.5min\n",
      "[CV 1/3; 4/32] START model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=rbf\n",
      "[CV 3/3; 2/32] END model__C=0.1, model__class_weight=balanced, model__kernel=rbf;, score=-0.315 total time=27.7min\n",
      "[CV 2/3; 4/32] START model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=rbf\n",
      "[CV 1/3; 3/32] END model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=linear;, score=-0.364 total time=24.9min\n",
      "[CV 3/3; 4/32] START model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=rbf\n",
      "[CV 1/3; 4/32] END model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=rbf;, score=-0.339 total time=23.4min\n",
      "[CV 1/3; 5/32] START model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=linear\n",
      "[CV 3/3; 3/32] END model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=linear;, score=-0.390 total time=27.8min\n",
      "[CV 2/3; 5/32] START model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=linear\n",
      "[CV 2/3; 4/32] END model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=rbf;, score=-0.320 total time=22.5min\n",
      "[CV 3/3; 5/32] START model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=linear\n",
      "[CV 3/3; 4/32] END model__C=0.1, model__class_weight={0: 1, 1: 1.7}, model__kernel=rbf;, score=-0.315 total time=25.6min\n",
      "[CV 1/3; 6/32] START model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=rbf\n",
      "[CV 1/3; 5/32] END model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=linear;, score=-0.364 total time=14.5min\n",
      "[CV 2/3; 6/32] START model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=rbf\n",
      "[CV 2/3; 5/32] END model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=linear;, score=-0.341 total time=15.4min\n",
      "[CV 3/3; 6/32] START model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=rbf\n",
      "[CV 1/3; 6/32] END model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=rbf;, score=-0.345 total time=15.1min\n",
      "[CV 1/3; 7/32] START model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=linear\n",
      "[CV 3/3; 5/32] END model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=linear;, score=-0.369 total time=19.3min\n",
      "[CV 2/3; 7/32] START model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=linear\n",
      "[CV 2/3; 6/32] END model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=rbf;, score=-0.338 total time=15.5min\n",
      "[CV 3/3; 7/32] START model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=linear\n",
      "[CV 3/3; 6/32] END model__C=0.1, model__class_weight={0: 1, 1: 2}, model__kernel=rbf;, score=-0.362 total time=18.1min\n",
      "[CV 1/3; 8/32] START model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=rbf\n",
      "[CV 1/3; 8/32] END model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=rbf;, score=-0.490 total time=17.3min\n",
      "[CV 2/3; 8/32] START model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=rbf\n",
      "[CV 3/3; 7/32] END model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=linear;, score=-0.500 total time=34.2min\n",
      "[CV 3/3; 8/32] START model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=rbf\n",
      "[CV 2/3; 8/32] END model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=rbf;, score=-0.492 total time=17.9min\n",
      "[CV 1/3; 9/32] START model__C=1, model__class_weight=balanced, model__kernel=linear\n",
      "[CV 2/3; 7/32] END model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=linear;, score=-0.500 total time=57.4min\n",
      "[CV 2/3; 9/32] START model__C=1, model__class_weight=balanced, model__kernel=linear\n",
      "[CV 3/3; 8/32] END model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=rbf;, score=-0.494 total time=23.2min\n",
      "[CV 3/3; 9/32] START model__C=1, model__class_weight=balanced, model__kernel=linear\n",
      "[CV 1/3; 7/32] END model__C=0.1, model__class_weight={0: 1, 1: 5}, model__kernel=linear;, score=-0.500 total time=108.0min\n",
      "[CV 1/3; 10/32] START model__C=1, model__class_weight=balanced, model__kernel=rbf\n",
      "[CV 1/3; 10/32] END model__C=1, model__class_weight=balanced, model__kernel=rbf;, score=-0.328 total time=12.5min\n",
      "[CV 2/3; 10/32] START model__C=1, model__class_weight=balanced, model__kernel=rbf\n",
      "[CV 2/3; 10/32] END model__C=1, model__class_weight=balanced, model__kernel=rbf;, score=-0.289 total time=12.8min\n",
      "[CV 3/3; 10/32] START model__C=1, model__class_weight=balanced, model__kernel=rbf\n",
      "[CV 3/3; 10/32] END model__C=1, model__class_weight=balanced, model__kernel=rbf;, score=-0.305 total time=16.4min\n",
      "[CV 1/3; 11/32] START model__C=1, model__class_weight={0: 1, 1: 1.7}, model__kernel=linear\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 29\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_search_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     19\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     20\u001b[0m         pipeline,\n\u001b[1;32m     21\u001b[0m         param_distributions\u001b[38;5;241m=\u001b[39mmodel_param_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mmodel_num_jobs,\n\u001b[1;32m     27\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Save best model\u001b[39;00m\n\u001b[1;32m     32\u001b[0m best_estimators_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train SVC\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "\n",
    "if \"SVC\" in model_param_dict:\n",
    "    model_start_time = time.time()\n",
    "    print(\"Processing SVC now...\")\n",
    "    \n",
    "    model = SVC()\n",
    "    pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "    if model_search_method == \"grid\":\n",
    "        search = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=model_param_dict[\"SVC\"],\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            n_jobs=model_num_jobs,\n",
    "            verbose=10\n",
    "        )\n",
    "    elif model_search_method == \"random\":\n",
    "        search = RandomizedSearchCV(\n",
    "            pipeline,\n",
    "            param_distributions=model_param_dict[\"SVC\"],\n",
    "            n_iter=model_num_iter,\n",
    "            cv=model_cv_num,\n",
    "            scoring=model_scoring,\n",
    "            random_state=model_random_state,\n",
    "            n_jobs=model_num_jobs,\n",
    "        )\n",
    "    else :\n",
    "        search = HalvingGridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid=model_param_dict[\"SVC\"],\n",
    "    factor=2,  # Prune half the models at each step\n",
    "    cv=model_cv_num,\n",
    "    scoring=model_scoring,\n",
    "    n_jobs=model_num_jobs,\n",
    "    verbose=10\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    search.fit(X_train, Y_train)\n",
    "\n",
    "    # Save best model\n",
    "    best_estimators_dict[\"SVC\"] = search.best_estimator_\n",
    "    print(\"Best parameters for SVC:\", search.best_params_)\n",
    "\n",
    "    model_end_time = time.time()\n",
    "    model_total_time = model_end_time - model_start_time\n",
    "    model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "    print(f\"SVC has run tuning for {model_duration:.3f} {model_tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8035bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train MLP\n",
    "# if \"MLP\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing MLP now...\")\n",
    "    \n",
    "#     model = MLPClassifier(random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"MLP\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"MLP\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"MLP\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for MLP:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"MLP has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Naive Bayes\n",
    "# if \"Naive Bayes\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing Naive Bayes now...\")\n",
    "    \n",
    "#     model = BernoulliNB()\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"Naive Bayes\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"Naive Bayes\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"Naive Bayes\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for Naive Bayes:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"Naive Bayes has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f5b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train XG Boost\n",
    "# if \"XG Boost\" in model_param_dict:\n",
    "#     model_start_time = time.time()\n",
    "#     print(\"Processing XG Boost now...\")\n",
    "    \n",
    "#     model = XGBClassifier(objective=\"reg:squarederror\", random_state=model_random_state)\n",
    "#     pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "#     if model_search_method == \"grid\":\n",
    "#         search = GridSearchCV(\n",
    "#             pipeline,\n",
    "#             param_grid=model_param_dict[\"XG Boost\"],\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#             verbose=3\n",
    "#         )\n",
    "#     elif model_search_method == \"random\":\n",
    "#         search = RandomizedSearchCV(\n",
    "#             pipeline,\n",
    "#             param_distributions=model_param_dict[\"XG Boost\"],\n",
    "#             n_iter=model_num_iter,\n",
    "#             cv=model_cv_num,\n",
    "#             scoring=model_scoring,\n",
    "#             random_state=model_random_state,\n",
    "#             n_jobs=model_num_jobs,\n",
    "#         )\n",
    "\n",
    "#     search.fit(X_train, Y_train)\n",
    "\n",
    "#     # Save best model\n",
    "#     best_estimators_dict[\"XG Boost\"] = search.best_estimator_\n",
    "#     print(\"Best parameters for XG Boost:\", search.best_params_)\n",
    "\n",
    "#     model_end_time = time.time()\n",
    "#     model_total_time = model_end_time - model_start_time\n",
    "#     model_duration, model_tag = duration_cal.duration_cal(model_total_time)\n",
    "#     print(f\"XG Boost has run tuning for {model_duration:.3f} {model_tag}\")\n",
    "#     print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebce2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87885cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "part4_time = time.time()\n",
    "part4_duration, part4_tag = duration_cal.duration_cal(part4_time - part3_time)\n",
    "print(f\"Part 4 has run for {part4_duration:.3f} {part4_tag}!\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate pre-selected models to get mean-squared error and r^2 values to determine which model is better for current dataset\n",
    "print(\"5. Evaluating machine learning model...\")\n",
    "model_eval.model_evaluation(X_test, Y_test, best_estimators_dict)\n",
    "print(\"Evaluation done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c775fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "part5_time = time.time()\n",
    "part5_duration, part5_tag = duration_cal.duration_cal(part5_time - part4_time)\n",
    "print(f\"Part 5 has run for {part5_duration:.3f} {part5_tag}!\")\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29167f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "final_time = end_time - start_time\n",
    "final_duration, final_tag = duration_cal.duration_cal(final_time)\n",
    "\n",
    "print(\"Script has reached end of line - It will terminate now!\")\n",
    "print(f\"Script has run for {final_duration:.3f} {final_tag}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8204839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file\n",
    "results_df = pd.DataFrame(best_estimators_dict).T\n",
    "results_df.to_csv(\"model_results.csv\", index=True)\n",
    "print(\"Results saved to 'model_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
